"""Content Generator agent - generates lecture content using Mamay LLM.

This agent:
1. Takes retrieved context from topic router
2. Uses Mamay LLM to generate structured lecture content
3. Creates control questions for comprehension check
4. Tracks sources for grounding
"""
from typing import Any, Dict, List, Optional

from ..llm.mamay import MamayLLM


class ContentGenerator:
    """Generator for structured lecture content using Mamay LLM.
    
    Produces:
    - Topic explanation appropriate for grade level
    - Key concepts and definitions
    - Examples and illustrations
    - Control questions for comprehension
    """
    
    def __init__(self):
        """Initialize ContentGenerator with Mamay LLM client."""
        self.llm = MamayLLM()
    
    def generate(
        self,
        query: str,
        topic: str,
        retrieved_docs: List[str],
        grade: int = 9,
        subject: str = "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞",
        personalization_prompt: Optional[str] = None,
        source_info: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Generate lecture content based on query and retrieved context.
        
        Args:
            query: Original teacher query
            topic: Matched topic name
            retrieved_docs: List of retrieved document texts (context)
            grade: Grade level (8 or 9)
            subject: Subject name
            personalization_prompt: Optional prompt_injection from PersonalizationEngine
            source_info: Optional source metadata for grounding
            
        Returns:
            Dict with:
                - "lecture_content": str - Generated lecture text
                - "control_questions": List[str] - Comprehension questions
                - "sources": List[str] - Source references for grounding
        """
        # Build context from retrieved documents (limit size to avoid timeout)
        context = self._build_context(retrieved_docs, max_chars=8000)
        print(f"[Content Generator] Context: {len(context)} chars from {len(retrieved_docs)} docs")
        
        # Log personalization data
        if personalization_prompt:
            print(f"[Content Generator] üéØ Personalization prompt:")
            for line in personalization_prompt.split('\n')[:5]:  # Show first 5 lines
                if line.strip():
                    print(f"[Content Generator]    {line.strip()}")
        else:
            print("[Content Generator] No personalization data available")
        
        # Build the prompt
        prompt = self._build_prompt(
            query=query,
            topic=topic,
            context=context,
            grade=grade,
            subject=subject,
            personalization_prompt=personalization_prompt
        )
        
        # Generate content using Mamay
        system_prompt = self._get_system_prompt(subject, grade)
        
        print("[Content Generator] Calling Mamay LLM...")
        response = self.llm.generate(
            prompt=prompt,
            system=system_prompt,
            temperature=0.7,
            max_tokens=4000
        )
        print("[Content Generator] LLM response received")
        
        # Parse the response
        lecture_content, control_questions = self._parse_response(response)
        
        # Extract and format sources
        sources = self._extract_sources(retrieved_docs, source_info)
        
        return {
            "lecture_content": lecture_content,
            "control_questions": control_questions,
            "sources": sources
        }
    
    def _build_context(self, retrieved_docs: List[str], max_chars: int = 6000) -> str:
        """Combine retrieved documents into a single context string.
        
        Limits total context size to avoid LLM timeout.
        Uses up to 5 docs, max 1500 chars each.
        """
        if not retrieved_docs:
            return ""
        
        context_parts = []
        total_chars = 0
        
        # Use first 5 docs
        for doc in retrieved_docs[:5]:
            # Truncate individual docs to 1500 chars
            doc_text = doc[:1500] if len(doc) > 1500 else doc
            
            if total_chars + len(doc_text) > max_chars:
                break
            
            context_parts.append(doc_text)
            total_chars += len(doc_text) + 2
        
        return "\n\n".join(context_parts)
    
    def _get_system_prompt(self, subject: str, grade: int) -> str:
        """Get system prompt for content generation."""
        return f"""–¢–∏ –¥–æ—Å–≤—ñ–¥—á–µ–Ω–∏–π –≤—á–∏—Ç–µ–ª—å {subject} –¥–ª—è —É—á–Ω—ñ–≤ {grade} –∫–ª–∞—Å—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó —à–∫–æ–ª–∏ –∑ –±–∞–≥–∞—Ç–æ—Ä—ñ—á–Ω–∏–º –¥–æ—Å–≤—ñ–¥–æ–º.

–¢–≤–æ—è –º—ñ—Å—ñ—è:
- –°—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ –≥–ª–∏–±–æ–∫—ñ, –∑–º—ñ—Å—Ç–æ–≤–Ω—ñ —Ç–∞ –∑–∞—Ö–æ–ø–ª—é—é—á—ñ –Ω–∞–≤—á–∞–ª—å–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏
- –ü–æ—è—Å–Ω—é–≤–∞—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ü—ñ—ó –ø—Ä–æ—Å—Ç–æ—é –º–æ–≤–æ—é –∑ —è—Å–∫—Ä–∞–≤–∏–º–∏ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏
- –ê–¥–∞–ø—Ç—É–≤–∞—Ç–∏ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –ø—ñ–¥ —Ä—ñ–≤–µ–Ω—å —Ç–∞ –ø–æ—Ç—Ä–µ–±–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —É—á–Ω—è
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —Å—É—á–∞—Å–Ω—ñ –ø–µ–¥–∞–≥–æ–≥—ñ—á–Ω—ñ –ø—ñ–¥—Ö–æ–¥–∏

–°—Ç–∏–ª—å –≤–∏–∫–ª–∞–¥–∞–Ω–Ω—è:
- –ß—ñ—Ç–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑ –ª–æ–≥—ñ—á–Ω–∏–º–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞–º–∏ –º—ñ–∂ —Ç–µ–º–∞–º–∏
- –ü—Ä–∏–∫–ª–∞–¥–∏ –∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∂–∏—Ç—Ç—è, –±–ª–∏–∑—å–∫—ñ –ø—ñ–¥–ª—ñ—Ç–∫–∞–º
- –ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ —Ñ–æ—Ä–º—É–ª–∏ –∑–∞–ø–∏—Å—É–π —É —Ñ–æ—Ä–º–∞—Ç—ñ LaTeX ($—Ñ–æ—Ä–º—É–ª–∞$)
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ç–∞–±–ª–∏—Ü—ñ —Ç–∞ —Å–ø–∏—Å–∫–∏ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Å–ø—Ä–∏–π–Ω—è—Ç—Ç—è
- –î–æ–¥–∞–≤–∞–π –∫–æ—Ä–æ—Ç–∫—ñ —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ —Ñ–∞–∫—Ç–∏ –∞–±–æ —Ü—ñ–∫–∞–≤–∏–Ω–∫–∏ –¥–µ –¥–æ—Ä–µ—á–Ω–æ
- –ë—É–¥—å –¥—Ä—É–∂–Ω—ñ–º, –ø—ñ–¥—Ç—Ä–∏–º—É—é—á–∏–º —Ç–∞ –º–æ—Ç–∏–≤—É—é—á–∏–º"""

    def _build_prompt(
        self,
        query: str,
        topic: str,
        context: str,
        grade: int,
        subject: str,
        personalization_prompt: Optional[str] = None
    ) -> str:
        """Build the generation prompt."""
        # Build personalization section with specific instructions
        personalization_section = ""
        if personalization_prompt:
            personalization_section = f"""

üéØ –ü–ï–†–°–û–ù–ê–õ–Ü–ó–ê–¶–Ü–Ø –î–õ–Ø –£–ß–ù–Ø:
{personalization_prompt}

–í–†–ê–•–û–í–£–ô –¶–Ü –î–ê–ù–Ü –ü–†–ò –°–¢–í–û–†–ï–ù–ù–Ü –ö–û–ù–¢–ï–ù–¢–£:
- –Ø–∫—â–æ —É—á–µ–Ω—å –º–∞—î –Ω–∏–∑—å–∫–∏–π –±–∞–ª - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –ø—Ä–æ—Å—Ç—ñ—à—ñ –ø–æ—è—Å–Ω–µ–Ω–Ω—è, –±—ñ–ª—å—à–µ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
- –Ø–∫—â–æ —É—á–µ–Ω—å –º–∞—î –≤–∏—Å–æ–∫–∏–π –±–∞–ª - –¥–æ–¥–∞–π —Å–∫–ª–∞–¥–Ω—ñ—à—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ —Ç–∞ –ø–æ–≥–ª–∏–±–ª–µ–Ω–Ω—è —Ç–µ–º–∏
- –Ø–∫—â–æ —î —Å–ª–∞–±–∫—ñ —Ç–µ–º–∏ - –Ω–∞–≥–æ–ª–æ—Å–∏ –Ω–∞ –∑–≤'—è–∑–∫–∞—Ö –∑ –Ω–∏–º–∏ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è
"""
        else:
            personalization_section = "\n(–ü–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥ –¥–ª—è —Å–µ—Ä–µ–¥–Ω—å–æ–≥–æ —É—á–Ω—è)"
        
        prompt = f"""–°—Ç–≤–æ—Ä–∏ –ì–õ–ò–ë–û–ö–ò–ô –¢–ê –î–ï–¢–ê–õ–¨–ù–ò–ô –∫–æ–Ω—Å–ø–µ–∫—Ç —É—Ä–æ–∫—É –¥–ª—è —É—á–Ω—è {grade} –∫–ª–∞—Å—É –∑ –ø—Ä–µ–¥–º–µ—Ç—É "{subject}".

üìö –¢–ï–ú–ê: {topic}
‚ùì –ó–ê–ü–ò–¢ –í–ß–ò–¢–ï–õ–Ø: {query}
{personalization_section}

üìñ –ö–û–ù–¢–ï–ö–°–¢ –ó –ü–Ü–î–†–£–ß–ù–ò–ö–ê:
\"\"\"
{context}
\"\"\"

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–í–ò–ú–û–ì–ò –î–û –ö–û–ù–°–ü–ï–ö–¢–£ (—Å—Ç–≤–æ—Ä–∏ –†–û–ó–ì–û–†–ù–£–¢–ò–ô –º–∞—Ç–µ—Ä—ñ–∞–ª):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

## üéØ –í—Å—Ç—É–ø
- –ß–æ–º—É —Ü—è —Ç–µ–º–∞ –≤–∞–∂–ª–∏–≤–∞ –¥–ª—è —É—á–Ω—è —Ç–∞ –¥–µ –≤–æ–Ω–∞ –∑–∞—Å—Ç–æ—Å–æ–≤—É—î—Ç—å—Å—è
- –ö–æ—Ä–æ—Ç–∫–∞ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∞ –¥–æ–≤—ñ–¥–∫–∞ –∞–±–æ —Ü—ñ–∫–∞–≤–∏–π —Ñ–∞–∫—Ç (—è–∫—â–æ –¥–æ—Ä–µ—á–Ω–æ)
- –©–æ —É—á–µ–Ω—å –∑–º–æ–∂–µ –∑—Ä–æ–±–∏—Ç–∏ –ø—ñ—Å–ª—è –≤–∏–≤—á–µ–Ω–Ω—è —Ç–µ–º–∏

## üìö –û—Å–Ω–æ–≤–Ω–∏–π –º–∞—Ç–µ—Ä—ñ–∞–ª

### –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞
- –ß—ñ—Ç–∫—ñ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –í–°–Ü–• –∫–ª—é—á–æ–≤–∏—Ö –ø–æ–Ω—è—Ç—å –∑ —Ç–µ–º–∏
- –ü–æ–∫—Ä–æ–∫–æ–≤—ñ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –∑ –ª–æ–≥—ñ—á–Ω–∏–º–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞–º–∏
- –í–∞–∂–ª–∏–≤—ñ —Ñ–æ—Ä–º—É–ª–∏/–ø—Ä–∞–≤–∏–ª–∞ (—É —Ñ–æ—Ä–º–∞—Ç—ñ LaTeX –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏)
- –ó–≤'—è–∑–æ–∫ –∑ —Ä–∞–Ω—ñ—à–µ –≤–∏–≤—á–µ–Ω–∏–º –º–∞—Ç–µ—Ä—ñ–∞–ª–æ–º

### –ü—Ä–∏–∫–ª–∞–¥–∏ —Ç–∞ –ø–æ—è—Å–Ω–µ–Ω–Ω—è
- 3-4 –¥–µ—Ç–∞–ª—å–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –∑ –ø–æ–∫—Ä–æ–∫–æ–≤–∏–º —Ä–æ–∑–≤'—è–∑–∫–æ–º
- –ü—Ä–∏–∫–ª–∞–¥–∏ –≤—ñ–¥ –ø—Ä–æ—Å—Ç–æ–≥–æ –¥–æ —Å–∫–ª–∞–¥–Ω–æ–≥–æ
- –¢–∏–ø–æ–≤—ñ –ø–æ–º–∏–ª–∫–∏ —Ç–∞ —è–∫ —ó—Ö —É–Ω–∏–∫–Ω—É—Ç–∏

## üí° –í–∞–∂–ª–∏–≤–æ –∑–∞–ø–∞–º'—è—Ç–∞—Ç–∏
- 5-7 –∫–ª—é—á–æ–≤–∏—Ö —Ñ–∞–∫—Ç—ñ–≤, —Ñ–æ—Ä–º—É–ª –∞–±–æ –ø—Ä–∞–≤–∏–ª
- –ú–Ω–µ–º–æ–Ω—ñ—á–Ω—ñ –ø—Ä–∏–π–æ–º–∏ –¥–ª—è –∑–∞–ø–∞–º'—è—Ç–æ–≤—É–≤–∞–Ω–Ω—è (—è–∫—â–æ —î)

## ‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ñ –ø–∏—Ç–∞–Ω–Ω—è
1. –ü–∏—Ç–∞–Ω–Ω—è –Ω–∞ —Ä–æ–∑—É–º—ñ–Ω–Ω—è —Ç–µ—Ä–º—ñ–Ω—ñ–≤
2. –ü–∏—Ç–∞–Ω–Ω—è –Ω–∞ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –ø—Ä–∞–≤–∏–ª
3. –ü–∏—Ç–∞–Ω–Ω—è –ø—ñ–¥–≤–∏—â–µ–Ω–æ—ó —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ (–∑ —Ñ–æ—Ä–º—É–ª–∞–º–∏ –≤ LaTeX, –¥–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ)

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ö†Ô∏è –í–ê–ñ–õ–ò–í–û:
- –ë–∞–∑—É–π—Å—è –¢–Ü–õ–¨–ö–ò –Ω–∞ –Ω–∞–¥–∞–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –∑ –ø—ñ–¥—Ä—É—á–Ω–∏–∫–∞
- –ù–ï –≤–∏–≥–∞–¥—É–π —Ñ–∞–∫—Ç–∏, —è–∫–∏—Ö –Ω–µ–º–∞—î –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ
- –ü–∏—à–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é
- –í—Å—ñ –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ –≤–∏—Ä–∞–∑–∏ –æ–≥–æ—Ä—Ç–∞–π —É –¥–æ–ª–∞—Ä–∏: $x^2$
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –µ–º–æ–¥–∑—ñ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É–≤–∞–Ω–Ω—è (–ø–æ–º—ñ—Ä–Ω–æ)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""

        return prompt
    
    def _parse_response(self, response: str) -> tuple[str, List[str]]:
        """Parse LLM response into lecture content and control questions.
        
        Returns:
            Tuple of (lecture_content, control_questions)
        """
        control_questions = []
        
        # Try to extract control questions section
        if "## –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ñ –ø–∏—Ç–∞–Ω–Ω—è" in response:
            parts = response.split("## –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ñ –ø–∏—Ç–∞–Ω–Ω—è")
            lecture_content = parts[0].strip()
            questions_section = parts[1] if len(parts) > 1 else ""
            
            # Parse questions (numbered list)
            for line in questions_section.split("\n"):
                line = line.strip()
                if line and (line[0].isdigit() or line.startswith("-")):
                    # Remove numbering/bullet
                    question = line.lstrip("0123456789.-) ").strip()
                    if question:
                        control_questions.append(question)
        else:
            # No clear separation - return full response as content
            lecture_content = response
        
        return lecture_content, control_questions
    
    def _extract_sources(
        self, 
        retrieved_docs: List[str], 
        source_info: Optional[Dict[str, Any]] = None
    ) -> List[str]:
        """Extract source references from retrieved documents.
        
        Args:
            retrieved_docs: List of document texts
            source_info: Optional dict with topic metadata:
                - subject, grade, topic_title, start_page, end_page
        
        Returns:
            List of formatted source strings for grounding
        """
        import re
        sources = []
        
        # 1. Primary source from topic metadata (highest quality)
        if source_info:
            subject = source_info.get("subject", "–ü—ñ–¥—Ä—É—á–Ω–∏–∫")
            grade = source_info.get("grade", "")
            topic_title = source_info.get("topic_title", "")
            start_page = source_info.get("start_page")
            end_page = source_info.get("end_page")
            
            # Build citation: "üìò –ê–ª–≥–µ–±—Ä–∞ 9 –∫–ª–∞—Å: ¬ß 11. –§—É–Ω–∫—Ü—ñ—è... (—Å—Ç–æ—Ä. 75-82)"
            book_ref = subject
            if grade:
                book_ref += f" {grade} –∫–ª–∞—Å"
            
            citation = f"üìò {book_ref}"
            if topic_title:
                citation += f": {topic_title}"
            
            if start_page:
                p_range = f"{start_page}-{end_page}" if (end_page and end_page != start_page) else str(start_page)
                citation += f" (—Å—Ç–æ—Ä. {p_range})"
            
            sources.append(citation)
        
        # 2. Extract page references from retrieved documents
        for i, doc in enumerate(retrieved_docs, 1):
            # Try to extract page number from format: "(—Å—Ç–æ—Ä—ñ–Ω–∫–∞ X)" or "PAGE: X"
            page_match = re.search(r"\(—Å—Ç–æ—Ä—ñ–Ω–∫–∞\s*(\d+)\)", doc)
            if page_match:
                sources.append(f"   ‚Ä¢ –°—Ç–æ—Ä—ñ–Ω–∫–∞ {page_match.group(1)}")
                continue
            
            page_match = re.search(r"PAGE:\s*(\d+)", doc)
            if page_match:
                sources.append(f"   ‚Ä¢ –°—Ç–æ—Ä—ñ–Ω–∫–∞ {page_match.group(1)}")
                continue
            
            # Try to extract topic from document
            topic_match = re.search(r"TOPIC:\s*([^\n]+)", doc)
            if topic_match:
                topic_name = topic_match.group(1).strip()[:50]
                sources.append(f"   ‚Ä¢ {topic_name}")
        
        # Deduplicate while preserving order
        seen = set()
        unique_sources = []
        for s in sources:
            if s not in seen:
                unique_sources.append(s)
                seen.add(s)
        
        return unique_sources[:10]  # Limit to 10 sources


def generate_content(state: dict) -> dict:
    """Node function for LangGraph workflow.
    
    Args:
        state: TutorState dictionary
        
    Returns:
        Dict with lecture_content, control_questions, sources, and error (if any)
    """
    print("[Content Generator] Generating lecture content...")
    
    # Get data from state
    query = state.get("teacher_query", "")
    grade = state.get("grade", 9)
    subject = state.get("subject", "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞")
    matched_topics = state.get("matched_topics", [])
    
    # Get personalization prompt from student_profile
    student_profile = state.get("student_profile")
    personalization_prompt = None
    if student_profile and isinstance(student_profile, dict):
        personalization_prompt = student_profile.get("prompt_injection")
    
    # Extract topic, retrieved docs, and source_info from matched_topics
    topic = ""
    retrieved_docs = []
    source_info = None
    
    if matched_topics:
        first_match = matched_topics[0]
        if isinstance(first_match, dict):
            topic = first_match.get("topic", "")
            retrieved_docs = first_match.get("retrieved_docs", [])
            source_info = first_match.get("source_info")
        elif isinstance(first_match, str):
            topic = first_match
    
    # Also include matched_pages if available
    matched_pages = state.get("matched_pages", [])
    for page in matched_pages:
        if isinstance(page, dict):
            content = page.get("content", "")
            if content and content not in retrieved_docs:
                retrieved_docs.append(content)
        elif isinstance(page, str) and page not in retrieved_docs:
            retrieved_docs.append(page)
    
    # Check if we have context to work with
    if not retrieved_docs:
        print("[Content Generator] Warning: No retrieved documents available")
        return {
            "lecture_content": "",
            "control_questions": [],
            "sources": [],
            "error": None
        }
    
    try:
        generator = ContentGenerator()
        result = generator.generate(
            query=query,
            topic=topic,
            retrieved_docs=retrieved_docs,
            grade=grade,
            subject=subject,
            personalization_prompt=personalization_prompt,
            source_info=source_info
        )
        
        print(f"[Content Generator] Generated {len(result['lecture_content'])} chars of content")
        print(f"[Content Generator] Created {len(result['control_questions'])} control questions")
        print(f"[Content Generator] Extracted {len(result['sources'])} sources")
        
        return {
            "lecture_content": result["lecture_content"],
            "control_questions": result["control_questions"],
            "sources": result["sources"],
            "error": None
        }
        
    except Exception as e:
        print(f"[Content Generator] Error: {e}")
        return {
            "lecture_content": "",
            "control_questions": [],
            "sources": [],
            "error": f"Content generation failed: {str(e)}"
        }
